{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning Basic Principles 2018 - Data Analysis Project Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the text in italics is instructions for filling the template - remove when writing the project report!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Title* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Title should be concise and informative, describes the approach to solve the problem. Some good titles from previous years:*\n",
    "\n",
    "*- Comparing extreme learning machines and naive bayes’ classifier in spam detection*\n",
    "\n",
    "*- Using linear discriminant analysis in spam detection*\n",
    "\n",
    "*Some not-so-good titles:*\n",
    "\n",
    "*- Bayesian spam filtering with extras*\n",
    "\n",
    "*- Two-component classifier for spam detection*\n",
    "\n",
    "*- CS-E3210 Term Project, final report*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Precise summary of the whole report, previews the contents and results. Must be a single paragraph between 100 and 200 words.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The focus of this project is to be able to correctly classify songs into genres based on on a set of features gathered from each song. To do this the songs feature sets have been divided into a training and a test set, and labels provided for the training set.\n",
    "\n",
    "The problem is an interesting machine learning task as the amount of data(songs) available worldwide is quite huge and the solution could have many applications, for example in providing users of different music services with a way to find new music based on a genre they like.\n",
    "\n",
    "It will also be a interesting learning process as it involve all parts of a Machine learning problem. The first task is to analyse the provided data, and pre-process it so that errors in the data set or large differences in value orders do not interfere with the classification process.\n",
    "\n",
    "The second part is to select an appropriate classification method. As there are quite a lot of different methods available there will be some need for experimentation and testing before finding good candidates to pursue further.\n",
    "\n",
    "The actual testing of the solution will be tested via two [Kaggle](#refs) competitions. One for accuracy of the predicted labels and one for the Log Loss value of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the classification process the data set need to be understood and cleaned up. So that errors in the data set does not negatively affect the classification and before that the normalization process.\n",
    "\n",
    "The data visualization and clean up was done in Matlab. The script used to clean up the data set can be found in [Appendix A](#appA). The clean up and normalization choices are described below.\n",
    "\n",
    "As described in the DAP inctructions [document](#refs), the feature set consists of X larger parts with their separate bands and characteristics. The amount of different separate characteristics was not so large that manual inspection, via visualization, proved more resource efficient than implementing a checking algorithm.\n",
    "\n",
    "The features were visualized with [Matlab](#refs) on a characteristics basis, that is all bands of a characteristics were plotted as a line plot for each instance in the data set. For an example see the figure below. As can be seen from the figure the individual lines are not clear but if any data points were to be in another order of magnitude the plot would be skewed and it would be very noticeable. This method is of course only feasible with a small enough feature set that is well understood, but in this case it is good enough. Contour plots were also tried but to properly see the set of songs needed to be cut into small 100 count segments and that made it a not so practical approach.\n",
    "\n",
    "![Alt text](Viz.png \"Vizualization of Rythm means bands 1 to 24\")\n",
    "\n",
    "Another interesting aspect that could also be found while visualising the training set was the distribution of the labels, which is shown in the figure below. From the figure it is quite clear that the dataset is unbalanced and that class 1 is dominating. The provided [article](#refs) provided some ideas for how this could be tackled.\n",
    "\n",
    "![Alt text](dist_labels.png \"Distribution of labels\")\n",
    "\n",
    "Utilizing this method one instance of bad data was found. The first 4 bands on the YYYY characteristics were all 10 000 for all songs in the data set, whereas the remaining bands were in the range of 0 to 1, keeping the 10 000 in the data set would have largely skewed the dataset, when normalizing. There for it was concluded to set these to 0, as they were the same for all songs. Figures below shows the a contour map before and after the clean up for the first 50 songs.\n",
    "\n",
    "![Alt text](map_error.png \"Contour with error\")\n",
    "<center>*With errors uncorrected, all other values drowns out.*</center>\n",
    "\n",
    "\n",
    "![Alt text](map_norm.png \"Contour corrected and normalized\")\n",
    "<center>*With errors corrected, peaks visable.*</center>\n",
    "\n",
    "The normalization was also done in a controlled way. The feature set was normalized on a characteristics basis over all the bands belonging to that characteristics. For example features 1 to 24 were normalized with the maximum value found in this subgroup from all the songs. \n",
    "\n",
    "The test data set was also cleaned up and normalized in the same way. Afterwards the two sets were written in csv format for utilization in Python.\n",
    "\n",
    "[Appendix B](#appB) also explains the tested super sampling which did not in the end yield any better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "014a593ce82d342a60d749c7a2c46b7c",
     "grade": true,
     "grade_id": "cell-c3ef844c17cf4a1e",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methods and experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before choosing a final method to implement in [scikit learn](#refs) in Python, we decided to try the data set in Matlab’s quick [classifier app](#refs) to test different approaches before moving over to the python environment.\n",
    "\n",
    "In Matlab the normalized training data was tested and validated using both the cross fold and hold out [method](#refs). In this case however there were very small differences between the hold out and cross fold method. The data was trained using many of the different classifier options and from this a few different methods were chosen, based on their accuracy scores. During this stage we also tested different feature reduction methods but this had an negative effect on the outcome. Probably because the data set was already quite small. Also undersampling was tested to see if the imbalance of the labels could be handled that way but the effects were worse probably due to the same reasons as with feature reduction. These methods were then further tested in Python. The methods that yielded high results were, Deep Trees and different degrees of Support Vector Machines([SVM](#refs)).\n",
    "\n",
    "Implementing the methods in Python using the scikit package was quite straight forward. And after some further testing the final method chosen was the [Support Vector Classifier](#refs) with balanced class weight option. At this stage the already mentioned super sampling technique was also ruled out, this might have been because the oversampling leads to a higher over fitting.\n",
    "\n",
    "Support vector Machines build on the principle of constructing hyperplanes in higher dimensional space in order to achieve separation between the classes. In cases where complete separation can’t be achieved the metode utilizes a so called soft margin approach. Where a [hinge loss](#refs) function. The mathematical formulation is:\n",
    "\n",
    "$$ \\min_ {w, b, \\zeta} \\frac{1}{2} w^T w + C \\sum_{i=1}^{n} \\zeta_i $$\n",
    "\n",
    "$$ \\textrm{subject to } y_i (w^T \\phi (x_i) + b) \\geq 1 - \\zeta_i, $$\n",
    "\n",
    "$$ \\zeta_i \\geq 0, i=1, ..., n $$\n",
    "\n",
    "The dual of this is: \n",
    "\n",
    "$$\\min_{\\alpha} \\frac{1}{2} \\alpha^T Q \\alpha - e^T \\alpha $$\n",
    "\n",
    "$$\\textrm{subject to } y^T \\alpha = 0$$\n",
    "\n",
    "$$ 0 \\leq \\alpha_i \\leq C, i=1, ..., n $$\n",
    "\n",
    "Here $e$ is a vector with all elements being 1, $C>0$ acts as an upper bound. Q is a semidefinte positive matrix which components map the training vector into the higher dimensional space via the kernel funtion, $K(x_i, x_j) = \\phi (x_i)^T \\phi (x_j)$, fur further information please see the [documentation](#refs).\n",
    "\n",
    "With a decision function of:\n",
    "\n",
    "$$\\operatorname{sgn}(\\sum_{i=1}^n y_i \\alpha_i K(x_i, x) + \\rho)$$\n",
    "\n",
    "It should be noted however that SVM methods works with binary classes, which in turn means that multi class problems, such as this is turned into a set of binary problems.\n",
    "\n",
    "To compute the problem mostly default parameters were used, the final choice used was `Calibrated Classifier CV` with `LinearSVC` estimate and weighted classes, with C set to .\n",
    "\n",
    "From the scikit SVC function its possible to get the needed output for the accuracy part directly, but for the log loss output the `CalibratedClassifierCV` function has the needed subfunction `.predict_proba` to be utilized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials with ML algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results were achieved with the Calibrated Classifier CV with LinearSVC estimate and weighted classes. The achieved accuracy scores were 0.6917. This yielded a accuracy score of 0.59806 on kaggle.\n",
    "\n",
    "The log loss was similarly tested in Python using the built in functions which yielded a score of 0.9504503063156581 on the training set and later a score of 0.19165 in kaggle.\n",
    "\n",
    "The confusion matrix of the training set can be seen in the figure below. From the matrix it is clear that most errors comes from dealing with the 1st class, which is to be expected as that is the dominating one in the training set.\n",
    "\n",
    "![Alt text](confusion_matrix_One_VS_One.png \"Confusion matrix\")\n",
    "<center>*Confusion matrix of the training set.*</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was quite a difference between the training data sets scores and the one from kaggle, but this is to be expected as the methods used has some inherited over fitting that is hard to get rid of. The big suprise though was the difference in the log loss function were the kaggel score was better than the pyhton internal for the training set. For this we have not been able to find a good explanation. \n",
    "\n",
    "The results could definitely be improved open but might require some different approaches already on the data preparation and normalization stage. The classifier method used might also not be the best for this kind of a problem. However the chosen method managed to beat the benchmark by quite a big marigne, 10 percentage points. Also as the dataset was quite small it is probably not a good idea to go more advance modern methods which usually requires quite large amounts of data.\n",
    "\n",
    "However one improvment that could have been done would have been to implment some form of parameter optimizer to finds the optimal parameters for the SVC, something like the `.GridSearchCV`([ref](#refs)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='refs'></a>\n",
    "**Kaggle** https://www.kaggle.com/\n",
    "\n",
    "\n",
    "\n",
    "**MLBP 2018 Data Analysis Project** https://mycourses.aalto.fi/pluginfile.php/743413/mod_resource/content/14/MLBP%202018%20project%20description.pdf\n",
    "\n",
    "**Mathworks Matlab** https://se.mathworks.com/help/matlab/index.html\n",
    "\n",
    "**8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset, Jason Brownlee, August 19, 2015, Machine Learning Process**\n",
    "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "\n",
    "**Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.** http://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html\n",
    "\n",
    "**Matlab Classification learner app** https://se.mathworks.com/help/stats/classification-learner-app.html\n",
    "\n",
    "**Matlab Classification learner app, Select Data and Validation for Classification Problem**\n",
    "https://se.mathworks.com/help/stats/select-data-and-validation-for-classification-problem.html\n",
    "\n",
    "**Support vector machine**https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "**Scikit-learn:sklearn.svm.LinearSVC** http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "**Hinge Loss, Wikipedia** https://en.wikipedia.org/wiki/Hinge_loss\n",
    "\n",
    "**SVC mathematical explanation, SciKit-Learn** http://scikit-learn.org/stable/modules/svm.html#svc\n",
    "\n",
    "**Scikit-learn: sklearn.model_selection.GridSearchCV**\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A\n",
    "\n",
    "<a id='appA'></a>\n",
    "\n",
    "The matlab script utilized to clean up and normalize the data. \n",
    "\n",
    "```matlab\n",
    "%The training and test data sets need to be imported into matlab first\n",
    "%With variable names testdata and traindata\n",
    "Data = traindata;\n",
    "bands = 0:7;\n",
    "bands = bands*24;\n",
    "for i=1:7\n",
    "    max_B = max(Data{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Data{:,bands(i)+1:bands(i+1)} = Data{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "bands = 0:4;\n",
    "bands = bands.*12;\n",
    "bands = bands+168;\n",
    "\n",
    "for i=1:4\n",
    "    max_B = max(Data{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Data{:,bands(i)+1:bands(i+1)} = Data{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "bands = 0:4;\n",
    "bands = bands*12;\n",
    "bands = bands+216;\n",
    "Data{:,217:220} = 0;\n",
    "\n",
    "for i=1:4\n",
    "    max_B = max(Data{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Data{:,bands(i)+1:bands(i+1)} = Data{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "writetable(Data,'Data.csv')\n",
    "%test noramlization\n",
    "Test = testdata;\n",
    "bands = 0:7;\n",
    "bands = bands*24;\n",
    "for i=1:7\n",
    "    max_B = max(Test{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Test{:,bands(i)+1:bands(i+1)} = Test{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "bands = 0:4;\n",
    "bands = bands.*12;\n",
    "bands = bands+168;\n",
    "\n",
    "for i=1:4\n",
    "    max_B = max(Test{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Test{:,bands(i)+1:bands(i+1)} = Test{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "bands = 0:4;\n",
    "bands = bands*12;\n",
    "bands = bands+216;\n",
    "Data{:,217:220} = 0;\n",
    "\n",
    "for i=1:4\n",
    "    max_B = max(Test{:,bands(i)+1:bands(i+1)},[],'all');\n",
    "    Test{:,bands(i)+1:bands(i+1)} = Test{:,bands(i)+1:bands(i+1)}/max_B;\n",
    "end\n",
    "\n",
    "writetable(Test,'Test.csv')\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Appendix B\n",
    "\n",
    "<a id='appB'></a>\n",
    "\n",
    "One of the ides we tested before choosing the final method was to super sample the data set in an effort to combat the imbalance between the different classes. As we were afraid that this imbalance would lead bad accuracy, as was stated in the article posted on slack. This however did not in the ned lead to any noticeable increase in accuracy so the it was decided that it is better to go with the simplest solution that achieves good enough results. The matlab code used to generate the supersampled data set is anyway added for curiosa. \n",
    "\n",
    "\n",
    "```matlab\n",
    "%The training and test datasets as well as training labels need to be imported into matlab first\n",
    "%With variable names testdata and traindata, trainlabels\n",
    "index1 = find(trainlabels{:,:} == 1);\n",
    "index2 = find(trainlabels{:,:} == 2);\n",
    "index3 = find(trainlabels{:,:} == 3);\n",
    "index4 = find(trainlabels{:,:} == 4);\n",
    "index5 = find(trainlabels{:,:} == 5);\n",
    "index6 = find(trainlabels{:,:} == 6);\n",
    "index7 = find(trainlabels{:,:} == 7);\n",
    "index8 = find(trainlabels{:,:} == 8);\n",
    "index9 = find(trainlabels{:,:} == 9);\n",
    "index10 = find(trainlabels{:,:} == 10);\n",
    "\n",
    "N_target = size(index1,1);\n",
    "SData = Data;\n",
    "SLabels = trainlabels;\n",
    "\n",
    "N2 = size(index2,1);\n",
    "\n",
    "for i = 1:(N2)\n",
    "    j = randi(N2);\n",
    "    SData = [SData; SData(index2(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index2(j),:)];\n",
    "end\n",
    "\n",
    "N3 = size(index3,1);\n",
    "\n",
    "for i = 1:(N3)\n",
    "    j = randi(N3);\n",
    "    SData = [SData; SData(index3(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index3(j),:)];\n",
    "end\n",
    "\n",
    "N4 = size(index4,1);\n",
    "\n",
    "for i = 1:(N4)\n",
    "    j = randi(N4);\n",
    "    SData = [SData; SData(index4(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index4(j),:)];\n",
    "end\n",
    "\n",
    "N5 = size(index5,1);\n",
    "\n",
    "for i = 1:(N5)\n",
    "    j = randi(N5);\n",
    "    SData = [SData; SData(index5(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index5(j),:)];\n",
    "end\n",
    "\n",
    "N6 = size(index6,1);\n",
    "\n",
    "for i = 1:(N6)\n",
    "    j = randi(N6);\n",
    "    SData = [SData; SData(index6(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index6(j),:)];\n",
    "end\n",
    "\n",
    "N7 = size(index7,1);\n",
    "\n",
    "for i = 1:(N7)\n",
    "    j = randi(N7);\n",
    "    SData = [SData; SData(index7(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index7(j),:)];\n",
    "end\n",
    "\n",
    "N8 = size(index8,1);\n",
    "\n",
    "for i = 1:(N8)\n",
    "    j = randi(N8);\n",
    "    SData = [SData; SData(index8(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index8(j),:)];\n",
    "end\n",
    "%% \n",
    "\n",
    "N9 = size(index9,1);\n",
    "\n",
    "for i = 1:(N9)\n",
    "    j = randi(N9);\n",
    "    SData = [SData; SData(index9(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index9(j),:)];\n",
    "end\n",
    "\n",
    "N10 = size(index10,1);\n",
    "\n",
    "for i = 1:(N10)\n",
    "    j = randi(N10);\n",
    "    SData = [SData; SData(index10(j),:)];\n",
    "    SLabels = [SLabels; SLabels(index10(j),:)];\n",
    "end\n",
    "\n",
    "SLabels.Properties.VariableNames{1} = 'Labels';\n",
    "SData_m = [SData SLabels];\n",
    "\n",
    "writetable(SData, 'SData.csv')\n",
    "writetable(SLabels, 'SLabels.csv')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
